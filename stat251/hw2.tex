\documentclass{article}
\usepackage{geometry}
\usepackage[namelimits,sumlimits]{amsmath}
\usepackage{amssymb,amsfonts}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage[cm]{fullpage}
\newcommand{\tab}{\hspace*{5em}}
\newcommand{\conj}{\overline}
\newcommand{\dd}{\partial}
\newcommand{\ep}{\epsilon}
\newcommand{\openm}{\begin{pmatrix}}
\newcommand{\closem}{\end{pmatrix}}
\DeclareMathOperator{\cov}{cov}
\newcommand{\nc}{\newcommand}
\newcommand{\rn}{\mathbb{R}}
\nc{\Pt}[1]{P(\text{#1})}
\nc{\nn}{\mathbb{N}}
\begin{document}
Name: Hall Liu

Date: \today 
\vspace{1.5cm}
\section*{Ch 3 problems}
\subsection*{3.32}
a. $\Pt{family has 1 child $|$ chosen child is eldest} = \frac{\Pt{chosen child is eldest $|$ family has 1 child}\Pt{family has 1 child}}{\Pt{chosen child is eldest}}$. The probability that the chosen child is eldest is $\sum_1^4 p_i/i=0.41\bar{6}$, where we add up the probabilities of a family having $i$ children ($p_i$) times the probability that the eldest is chosen out of $i$ ($1/i$). Probability that a family has 1 child is $p_1=0.1$, and the eldest child is certainly selected, so the overall probability is $0.24$. If we do this with the youngest child, the probability remains the same, since no probability here actually depends on the ordering of the ages of the children.

b. $\Pt{family has 4 children $|$ chosen child is eldest} = \frac{\Pt{chosen child is eldest $|$ family has 4 children}\Pt{family has 4 children}}{\Pt{chosen child is eldest}}$. The first probability in the numerator is $0.25$, $p_4=0.3$, so the overall probability is $0.18$. The answer remains the same again if we use the youngest child instead.
\subsection*{3.56}
We want to find $\Pt{$n$th coupon is a new coupon $|$ $n$th coupon is of type $i$}$ summed over $i$. This is equivalent to \\
$\Pt{$n$th coupon is of type $i$ $|$ no coupons before $n$ were of type $i$}$. Since the probability of receiving a coupon is independent of previously received coupons, this is just the product of the two probabilities, or $p_i(1-p_i)^{n-1}$. Sum this over $i$ to get the answer.
\subsection*{3.58}
a. We have $P(H)=\Pt{second flip is H}\Pt{first flip is T}=p(1-p)$ and $P(T)=\Pt{second flip is T}\Pt{first flip is H}=(1-p)p=P(H)$.

b. In this case, if the first flip is a T, we are guaranteed to end with an H since we take the flip that breaks the streak and H is the only thing that could break the streak. Similarly, if the first flip is a H, we are guaranteed to end with a T. Thus, if the coin is unfair to begin with, this will result in an equally unfair scheme.
\subsection*{3.64}
Option (a) gives the correct answer with probability $p$. In option (b), the probability of them giving the correct answer is $\Pt{they agree on the common answer}+\Pt{they disagree and the coin flip is in favor of the correct answer}$. The first probability is $p^2$, and the second probability is $2p(1-p)\cdot1/2=p(1-p)=p-p^2$, so the sum is still $p$. Thus, the strategies are equally good.
\subsection*{3.76}
The probability that event $E$ occurs before $F$ is equal to the sum over all natural numbers $n$ of $\Pt{Event $E$ occurs on the $n$th iteration $|$ neither event $E$ nor event $F$ occur before event $n$}$. Since iterations of experiments are independent, this reduces to a product. The first term is $P(E)$, and the second term is $(1-(P(E)+P(F)))^{n-1}$, since $E$ and $F$ are mutually exclusive. Thus, summing from $1$ to $\infty$ gives $\frac{P(E)}{P(E)+P(F)}$.
\subsection*{3.90}
Consider the complement of this, or when one of outcomes 1 or 2 fail to occur. Denote the former by $E$ and the latter by $F$. Then, we are looking for $P(E\cup F)=P(E)+P(F)-P(E\cap F)$. We have $P(E)=(p_0+p_2)^n$ (all outcomes are either 0 or 2), $P(F)=(p_0+p_1)^n$ (all outcomes are either 0 or 1), and $P(E\cap F)=p_0^n$ (all outcomes must be 0 for both 1 and 2 to fail to occur). Thus, the probability is $(p_0+p_1)^n+(p_0+p_2)^n-p_0^n$.
\section*{Ch 3 Theoretical Exercises}
\subsection*{3.5}
a. True. We have $P(F|E)=\frac{P(E|F)P(F)}{P(E)}\leq\frac{P(E)P(F)}{P(E)}=P(F)$. If we assume positive information, then $P(F|E)=\frac{P(E|F)P(F)}{P(E)}\geq\frac{P(E)P(F)}{P(E)}=P(F)$

b. False. Suppose $F=G$ and $F$ is disjoint from $E$. Then $P(E|F)=P(G|E)=0$, both less than or equal to $P(E)$ and $P(G)$, resp., but $P(G|F)=1\geq P(G)$.

c. False. Suppose we are choosing random integers uniformly distributed from $0$ to $10$. Let $G$ be the event of a number in $[0,7]$. $F$ be the event of a number in $[5,10]$, and $E=F\cap G$. Then $P(E|F)<1/2$ and $P(E|G)<1/2$, but $P(E|FG)=1$. 

If we use positive information in (b), it's still false: consider the random number thing again, let $F=[0,5]$, $E=[2,7]$, $G=[4,9]$. We have $P(E|F)=3/5>P(F)$ and $P(G|E)=3/5>P(G)$, but $P(G|F)=1/5<P(G)$.

If we use positive information in (c), it's still false: let $F=[0,4]$, $G=[4,8]$, and $E=\{0,8\}$. Then $P(E|F)=P(E|G)=1/4>P(E)=1/5$, but $E$ and $FG$ have empty intersection.
\subsection*{3.9}
We have $P(A)=1/2$, $P(B)=1/2$, and $P(C)=1/2$. $P(A\cap B)=\Pt{both heads}=1/4=P(A)P(B)$, $P(A\cap C)=\Pt{first is head and second is same as first}=1/4=P(A)P(C)$, and $P(B\cap C)=\Pt{second is head and first is same as second}=1/4=P(B)P(C)$. Thus they're pairwise independent. However, $P(A\cap B\cap C)=P(HH)=1/4\neq P(A)P(B)P(C)$.
\subsection*{3.21}
The computations are really tedious, so I'm just going to get the general case first and calculate them from there.

d. Suppose we know the values of $P_{n-1,m}$ and $P_{n,m-1}$. Then, $P_{n,m}=\frac{n}{n+m}\Pt{A is always ahead $|$ the last vote is for A}+\frac{m}{n+m}\Pt{A is always ahead $|$ the last vote is for B}$. For the first conditional, we have that $A$ is always ahead iff for the first $n+m-1$ ballots cast, $A$ was always ahead, since the last ballot being for $A$ will not change $A$ being ahead. A similar result holds for the second conditional, as the condition $n>m$ implies that $A$ will always be ahead after the last vote. Thus, we have $P_{n,m}=\frac{nP_{n-1,m}}{n+m}+\frac{mP_{n,m-1}}{n+m}$.

Now, for all $m\geq n$, fix $P_{n,m}=0$. For the base cases, we have $P_{n,0}=1$ for all $n$.

a.\begin{align*} 
    P_{2,1}&=P_{1,1}\frac{2}{3}+P_{2,0}\frac{1}{3}=1/3\\
    P_{3,1}&=P_{2,1}\frac{3}{4}+P_{3,0}\frac{1}{4}=1/2\\
    P_{3,2}&=P_{2,2}\cdots+P_{3,1}\frac{2}{5}=1/5\\
    P_{4,1}&=P_{3,1}\frac{4}{5}+P_{4,0}\frac{1}{5}=3/5\\
    P_{4,2}&=P_{3,2}\frac{4}{6}+P_{4,1}\frac{2}{6}=1/3\\
    P_{4,3}&=P_{3,3}\cdots+P_{4,2}\frac{3}{7}=1/7\\
\end{align*}

b. To find $P_{n,1}$, we note that there are $n+1$ places for the vote for $B$ to appear, and $A$ will always come out ahead if the vote appears after the second vote for $A$ has been counted. Thus the probability is $\frac{n-1}{n+1}$. To find $P_{n,2}$, we note that there are now $\frac{(n+2)(n+1)}{2}$ places for the two $B$ votes to go. $A$ fails to always be ahead if there is a $B$ vote in the first place or in the second place, or if there is a $B$ vote in both the third place and the fourth place. There are $n+1$ possibilities for the first case, $n$ for the second case, and $1$ for the third case, so we get $P_{n,2}=1-\frac{4n+4}{(n+2)(n+1)}=\frac{n-1}{n+2}$.

c,e. Hypothesis: $P_{n,m}=\frac{n-m}{n+m}$ for $n>m$ and $0$ otherwise. Proof: Statement is valid for base cases $P_{n,0}$ and $P_{0,m}$. Assume the inductive hypothesis for $P_{n',m'}$ if $n'<n$ or $m'<m$. Then, $P_{n,m}=\frac{n}{n+m}\frac{n-1-m}{n-1+m}+\frac{m}{n+m}\frac{n-m+1}{n+m-1}=\frac{n^2-n-nm+nm-m^2+m}{(n+m)(n+m-1)}=\frac{n-m}{n+m}$.
\subsection*{3.29}
Follow the notation of 5e, except let $H_m$ denote the event that the next $m$ flips are all heads. Now, $P(H_m|C_i)=\left(\frac{i}{k}\right)^m$, and $P(C_i|F_n)$ remains unchanged, so
$$P(H_m|F_n)=\frac{\sum_{i=0}^k\left(\frac{i}{k}\right)^{n+m}}{\sum_{j=0}^k(j/k)^n}\approx\frac{\int_0^1x^{n+m}}{\int_0^1x^n}=\frac{n+1}{n+m+1}$$
\section*{Additional Problems}
\subsection*{1}
Since the probability of going into each box is equal, we expect that $P(N_1=i)=P(N_2=j)$ if $i=j$. Then, 
$$P(N_1=i)=\sum_{N=i}^\infty P(N)P(N_1=i|\text{ total number of balls is }N)=\frac{1}{e}\sum_{N=i}^\infty\frac{\frac{N!}{(N-i)!i!}}{N!2^N}=\frac{1}{ei!2^i}\sum_{N=0}^\infty\frac{1}{N!2^{N}}=\frac{1}{\sqrt{e}i!2^i}$$
\subsection*{2}
Let $N$ denote the total number of balls. We have $P(N_1=i,N_2=j)=P(N_1=i,N=i+j)=P(N_1=i|N=i+j)P(N=i+j)=\binom{i+j}{i}\frac{1}{e(i+j)!}$.
\end{document}
